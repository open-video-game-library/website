export default (function(a,b,c,d,e,f,g,h,i,j,k,l,m,n,o,p,q,r,s,t,u,v,w,x,y,z,A,B,C,D,E,F,G,H,I,J,K,L,M,N,O,P,Q,R,S,T,U,V,W,X,Y,Z,_,$,aa,ab,ac,ad,ae,af,ag,ah,ai,aj,ak,al,am,an,ao,ap,aq,ar,as,at,au,av,aw,ax,ay,az,aA,aB,aC,aD,aE,aF,aG,aH,aI,aJ,aK,aL,aM,aN,aO,aP,aQ,aR,aS,aT,aU,aV,aW,aX,aY,aZ,a_,a$,ba,bb,bc,bd,be,bf,bg){return {data:{"content-query-dj1efWpr2V":[{_path:"\u002Farticle\u002Fdemovideo",_dir:r,_draft:e,_partial:e,_locale:s,_empty:e,title:"Research Introduction Video Released",description:"A video introducing our research was released in conjunction with our presentation at Interaction 2023.",excerpt:{type:h,children:[]},thumbnail:"https:\u002F\u002Fstorage.googleapis.com\u002Fstudio-design-asset-files\u002Fprojects\u002FbXqzm9GKOD\u002Fs-2400x1500_v-frms_webp_d5febd22-9b2a-472a-99fa-5ec6b9ac85eb.jpg",exlink:"https:\u002F\u002Fwww.youtube.com\u002Fwatch?v=PPrBhmzCpRQ",created_at:"2023.03.08",updated_at:l,body:{type:h,children:[],toc:{title:k,searchDepth:g,depth:g,links:[]}},_type:t,_id:"content:article:demovideo.md",_source:u,_file:"article\u002Fdemovideo.md",_extension:v},{_path:"\u002Farticle\u002Fces-result",_dir:r,_draft:e,_partial:e,_locale:s,_empty:e,title:"Results submission site for the Common Experience Sample is now open!",description:"In order to promote comparative evaluation of tactile displays among studies, we have created a posting site to share the results of experiments conducted using common experience samples.",excerpt:{type:h,children:[{type:a,tag:w,props:{id:Q},children:[{type:b,value:R}]},{type:a,tag:c,props:{},children:[{type:a,tag:i,props:{href:S,rel:[j]},children:[{type:b,value:T}]},{type:b,value:U}]},{type:a,tag:c,props:{},children:[{type:b,value:V}]},{type:a,tag:c,props:{},children:[{type:b,value:W}]},{type:a,tag:c,props:{},children:[{type:b,value:X}]},{type:a,tag:x,props:{alt:Y,src:Z},children:[]},{type:a,tag:w,props:{id:_},children:[{type:b,value:$}]},{type:a,tag:c,props:{},children:[{type:a,tag:i,props:{href:aa,rel:[j]},children:[{type:b,value:ab}]},{type:b,value:ac}]},{type:a,tag:c,props:{},children:[{type:b,value:ad}]},{type:a,tag:ae,props:{},children:[{type:a,tag:p,props:{},children:[{type:b,value:af}]},{type:a,tag:p,props:{},children:[{type:b,value:ag}]},{type:a,tag:p,props:{},children:[{type:b,value:ah}]},{type:a,tag:p,props:{},children:[{type:b,value:ai}]},{type:a,tag:p,props:{},children:[{type:b,value:aj}]}]},{type:a,tag:c,props:{},children:[{type:b,value:ak}]},{type:a,tag:c,props:{},children:[{type:b,value:al}]},{type:a,tag:c,props:{},children:[{type:b,value:am}]},{type:a,tag:w,props:{id:an},children:[{type:b,value:ao}]},{type:a,tag:c,props:{},children:[{type:b,value:ap},{type:a,tag:i,props:{href:D,rel:[j]},children:[{type:b,value:D}]},{type:b,value:E}]},{type:a,tag:m,props:{code:G,filename:F,language:F},children:[{type:a,tag:y,props:{},children:[{type:a,tag:m,props:{__ignoreMap:k},children:[{type:b,value:G}]}]}]}]},thumbnail:"https:\u002F\u002Fuser-images.githubusercontent.com\u002F52689532\u002F216533540-69085258-2064-412b-9c33-898a634e4bb2.png",exlink:l,created_at:"2023.03.06",updated_at:l,body:{type:h,children:[{type:a,tag:w,props:{id:Q},children:[{type:b,value:R}]},{type:a,tag:c,props:{},children:[{type:a,tag:i,props:{href:S,rel:[j]},children:[{type:b,value:T}]},{type:b,value:U}]},{type:a,tag:c,props:{},children:[{type:b,value:V}]},{type:a,tag:c,props:{},children:[{type:b,value:W}]},{type:a,tag:c,props:{},children:[{type:b,value:X}]},{type:a,tag:x,props:{alt:Y,src:Z},children:[]},{type:a,tag:w,props:{id:_},children:[{type:b,value:$}]},{type:a,tag:c,props:{},children:[{type:a,tag:i,props:{href:aa,rel:[j]},children:[{type:b,value:ab}]},{type:b,value:ac}]},{type:a,tag:c,props:{},children:[{type:b,value:ad}]},{type:a,tag:ae,props:{},children:[{type:a,tag:p,props:{},children:[{type:b,value:af}]},{type:a,tag:p,props:{},children:[{type:b,value:ag}]},{type:a,tag:p,props:{},children:[{type:b,value:ah}]},{type:a,tag:p,props:{},children:[{type:b,value:ai}]},{type:a,tag:p,props:{},children:[{type:b,value:aj}]}]},{type:a,tag:c,props:{},children:[{type:b,value:ak}]},{type:a,tag:c,props:{},children:[{type:b,value:al}]},{type:a,tag:c,props:{},children:[{type:b,value:am}]},{type:a,tag:w,props:{id:an},children:[{type:b,value:ao}]},{type:a,tag:c,props:{},children:[{type:b,value:ap},{type:a,tag:i,props:{href:D,rel:[j]},children:[{type:b,value:D}]},{type:b,value:E}]},{type:a,tag:m,props:{code:G,filename:F,language:F},children:[{type:a,tag:y,props:{},children:[{type:a,tag:m,props:{__ignoreMap:k},children:[{type:a,tag:d,props:{class:q},children:[{type:a,tag:d,props:{class:"ct-9766cd"},children:[{type:b,value:"@conference"}]},{type:a,tag:d,props:{class:f},children:[{type:b,value:"{"}]},{type:a,tag:d,props:{class:"ct-a3c894"},children:[{type:b,value:"oka2022ces"}]},{type:a,tag:d,props:{class:f},children:[{type:b,value:C}]}]},{type:a,tag:d,props:{class:q},children:[{type:a,tag:d,props:{class:f},children:[{type:b,value:z}]},{type:a,tag:d,props:{class:A},children:[{type:b,value:"author"}]},{type:a,tag:d,props:{class:f},children:[{type:b,value:"    = "}]},{type:a,tag:d,props:{class:n},children:[{type:b,value:o}]},{type:a,tag:d,props:{class:f},children:[{type:b,value:"拓也,岡 and 浩輔,森本 and 洋平,簗瀬 and 恵太,渡邊"}]},{type:a,tag:d,props:{class:n},children:[{type:b,value:o}]},{type:a,tag:d,props:{class:f},children:[{type:b,value:C}]}]},{type:a,tag:d,props:{class:q},children:[{type:a,tag:d,props:{class:f},children:[{type:b,value:z}]},{type:a,tag:d,props:{class:A},children:[{type:b,value:"title"}]},{type:a,tag:d,props:{class:f},children:[{type:b,value:H}]},{type:a,tag:d,props:{class:n},children:[{type:b,value:o}]},{type:a,tag:d,props:{class:f},children:[{type:b,value:"触覚ディスプレイの比較評価を目的とした共通体験サンプルの試作と検討"}]},{type:a,tag:d,props:{class:n},children:[{type:b,value:o}]}]},{type:a,tag:d,props:{class:q},children:[{type:a,tag:d,props:{class:f},children:[{type:b,value:z}]},{type:a,tag:d,props:{class:A},children:[{type:b,value:"booktitle"}]},{type:a,tag:d,props:{class:f},children:[{type:b,value:H}]},{type:a,tag:d,props:{class:n},children:[{type:b,value:o}]},{type:a,tag:d,props:{class:f},children:[{type:b,value:"第27回日本バーチャルリアリティ学会大会論文集"}]},{type:a,tag:d,props:{class:n},children:[{type:b,value:o}]},{type:a,tag:d,props:{class:f},children:[{type:b,value:C}]}]},{type:a,tag:d,props:{class:q},children:[{type:a,tag:d,props:{class:f},children:[{type:b,value:z}]},{type:a,tag:d,props:{class:A},children:[{type:b,value:"institution"}]},{type:a,tag:d,props:{class:f},children:[{type:b,value:"  = "}]},{type:a,tag:d,props:{class:n},children:[{type:b,value:o}]},{type:a,tag:d,props:{class:f},children:[{type:b,value:"明治大学大学院先端数理科学研究科先端メディアサイエンス専攻, 明治大学総合数理学部先端メディアサイエンス学科, ユニティ・テクノロジーズ・ジャパン株式会社, 明治大学総合数理学部先端メディアサイエンス学科"}]},{type:a,tag:d,props:{class:n},children:[{type:b,value:o}]},{type:a,tag:d,props:{class:f},children:[{type:b,value:C}]}]},{type:a,tag:d,props:{class:q},children:[{type:a,tag:d,props:{class:f},children:[{type:b,value:z}]},{type:a,tag:d,props:{class:A},children:[{type:b,value:"year"}]},{type:a,tag:d,props:{class:f},children:[{type:b,value:"      = "}]},{type:a,tag:d,props:{class:n},children:[{type:b,value:o}]},{type:a,tag:d,props:{class:f},children:[{type:b,value:"2022"}]},{type:a,tag:d,props:{class:n},children:[{type:b,value:o}]},{type:a,tag:d,props:{class:f},children:[{type:b,value:C}]}]},{type:a,tag:d,props:{class:q},children:[{type:a,tag:d,props:{class:f},children:[{type:b,value:z}]},{type:a,tag:d,props:{class:A},children:[{type:b,value:"month"}]},{type:a,tag:d,props:{class:f},children:[{type:b,value:H}]},{type:a,tag:d,props:{class:n},children:[{type:b,value:o}]},{type:a,tag:d,props:{class:f},children:[{type:b,value:"sep"}]},{type:a,tag:d,props:{class:n},children:[{type:b,value:o}]}]},{type:a,tag:d,props:{class:q},children:[{type:a,tag:d,props:{class:f},children:[{type:b,value:"}"}]}]}]}]}]},{type:a,tag:"style",children:[{type:b,value:".ct-5afef4{color:#A5D6FF}.ct-8ee602{color:#79C0FF}.ct-a3c894{color:#FFA657}.ct-769c3f{color:#C9D1D9}.ct-9766cd{color:#FF7B72}"}]}],toc:{title:k,searchDepth:g,depth:g,links:[]}},_type:t,_id:"content:article:ces-result.md",_source:u,_file:"article\u002Fces-result.md",_extension:v},{_path:"\u002Farticle\u002Fkudos2022",_dir:r,_draft:e,_partial:e,_locale:s,_empty:e,title:"Common experience samples were published in the research web media \"Kudos\".",description:"Common Experience Sample 1.0 Developing a sample for comparing the characteristics of haptic displays\" submitted to VRST2022 has been published in Kudos, a research web media.",excerpt:{type:h,children:[]},thumbnail:"https:\u002F\u002Fimages.unsplash.com\u002Fphoto-1592477725143-2e57dc728f0a?crop=entropy&cs=tinysrgb&fit=max&fm=jpg&ixid=Mnw1MzM4NXwwfDF8c2VhcmNofDN8fGhhcHRpY3xlbnwwfDB8fHwxNjY5MTY4MjEz&ixlib=rb-4.0.3&q=80&w=1080&w=1304",exlink:"https:\u002F\u002Fwww.growkudos.com\u002Fpublications\u002F10.1145%252F3562939.3565649\u002Freader",created_at:"2022.12.01",updated_at:l,body:{type:h,children:[],toc:{title:k,searchDepth:g,depth:g,links:[]}},_type:t,_id:"content:article:kudos2022.md",_source:u,_file:"article\u002Fkudos2022.md",_extension:v},{_path:"\u002Farticle\u002Fvrst2022",_dir:r,_draft:e,_partial:e,_locale:s,_empty:e,title:"Common Experience Sample (CES) presented at VRST2022",description:"M2 Oka presented a demo entitled \"Common Experience Sample 1.0 Developing a sample for comparing the characteristics of haptic displays\" at the 28th ACM Symposium on Virtual Reality Software and Technology (VRST2022). Common Experience Sample 1.0 Developing a sample for comparing the characteristics of haptic displays.",excerpt:{type:h,children:[]},thumbnail:"https:\u002F\u002Fstorage.googleapis.com\u002Fstudio-design-asset-files\u002Fprojects\u002FwQOVXEVxaD\u002Fs-2400x1800_v-frms_webp_73ff30e6-fd50-492c-8c19-e964dec18f92.webp",exlink:"https:\u002F\u002Fkeita-lab.jp\u002Fconference\u002Fvrst2022",created_at:"2022.11.29",updated_at:l,body:{type:h,children:[],toc:{title:k,searchDepth:g,depth:g,links:[]}},_type:t,_id:"content:article:vrst2022.md",_source:u,_file:"article\u002Fvrst2022.md",_extension:v},{_path:"\u002Farticle\u002Fah-aloud",_dir:r,_draft:e,_partial:e,_locale:s,_empty:e,title:"The \"Ah-Aloud Method\" was presented at an academic conference.",description:"Open video game use cases will also be presented. We have presented our method of observing emotions, called the \"Ah-Aloud Method\" at two conferences.",excerpt:{type:h,children:[{type:a,tag:B,props:{id:I},children:[{type:b,value:J}]},{type:a,tag:aq,props:{width:ar,height:as,style:at,src:au,title:av,frameBorder:aw,allow:ax,allowFullScreen:ay},children:[]},{type:a,tag:c,props:{},children:[{type:b,value:az}]},{type:a,tag:c,props:{},children:[{type:b,value:aA}]},{type:a,tag:c,props:{},children:[{type:b,value:aB}]},{type:a,tag:c,props:{},children:[{type:b,value:aC}]},{type:a,tag:c,props:{},children:[{type:b,value:aD}]},{type:a,tag:B,props:{id:K},children:[{type:b,value:L}]},{type:a,tag:c,props:{},children:[{type:b,value:aE}]},{type:a,tag:m,props:{code:M},children:[{type:a,tag:y,props:{},children:[{type:a,tag:m,props:{__ignoreMap:k},children:[{type:b,value:M}]}]}]},{type:a,tag:c,props:{},children:[{type:b,value:aF},{type:a,tag:i,props:{href:aG,rel:[j]},children:[{type:b,value:aH}]},{type:b,value:aI}]},{type:a,tag:c,props:{},children:[{type:b,value:aJ}]},{type:a,tag:m,props:{code:N},children:[{type:a,tag:y,props:{},children:[{type:a,tag:m,props:{__ignoreMap:k},children:[{type:b,value:N}]}]}]},{type:a,tag:c,props:{},children:[{type:a,tag:i,props:{href:aK,rel:[j]},children:[{type:b,value:aL}]},{type:b,value:aM}]},{type:a,tag:B,props:{id:O},children:[{type:b,value:P}]},{type:a,tag:c,props:{},children:[{type:b,value:aN}]},{type:a,tag:c,props:{},children:[{type:b,value:aO},{type:a,tag:i,props:{href:aP,rel:[j]},children:[{type:b,value:aQ}]},{type:b,value:aR},{type:a,tag:i,props:{href:aS,rel:[j]},children:[{type:b,value:aT}]},{type:b,value:E}]},{type:a,tag:c,props:{},children:[{type:a,tag:x,props:{alt:aU,src:aV},children:[]}]},{type:a,tag:c,props:{},children:[{type:b,value:aW}]},{type:a,tag:c,props:{},children:[{type:b,value:aX}]},{type:a,tag:c,props:{},children:[{type:b,value:aY}]},{type:a,tag:c,props:{},children:[{type:b,value:aZ}]},{type:a,tag:c,props:{},children:[{type:b,value:a_}]},{type:a,tag:c,props:{},children:[{type:b,value:a$},{type:a,tag:i,props:{href:ba,rel:[j]},children:[{type:b,value:bb}]},{type:b,value:bc}]},{type:a,tag:c,props:{},children:[{type:a,tag:x,props:{alt:bd,src:be},children:[]}]},{type:a,tag:c,props:{},children:[{type:b,value:bf}]},{type:a,tag:c,props:{},children:[{type:b,value:bg}]}]},thumbnail:"http:\u002F\u002Fimg.youtube.com\u002Fvi\u002FxpkJ13SegK4\u002Fmaxresdefault.jpg",exlink:l,created_at:"2022.11.19",updated_at:l,body:{type:h,children:[{type:a,tag:B,props:{id:I},children:[{type:b,value:J}]},{type:a,tag:aq,props:{width:ar,height:as,style:at,src:au,title:av,frameBorder:aw,allow:ax,allowFullScreen:ay},children:[]},{type:a,tag:c,props:{},children:[{type:b,value:az}]},{type:a,tag:c,props:{},children:[{type:b,value:aA}]},{type:a,tag:c,props:{},children:[{type:b,value:aB}]},{type:a,tag:c,props:{},children:[{type:b,value:aC}]},{type:a,tag:c,props:{},children:[{type:b,value:aD}]},{type:a,tag:B,props:{id:K},children:[{type:b,value:L}]},{type:a,tag:c,props:{},children:[{type:b,value:aE}]},{type:a,tag:m,props:{code:M},children:[{type:a,tag:y,props:{},children:[{type:a,tag:m,props:{__ignoreMap:k},children:[{type:a,tag:d,props:{class:q},children:[{type:a,tag:d,props:{},children:[{type:b,value:"川島 拓也, 渡邊 恵太. \"あアラウド法：体験中の心理プロセスを「あ」の音声情報で評価する手法の提案と検証\". エンタテインメントコンピューティングシンポジウム2022論文集, Vol. 2022, pp. 178-183, Aug. 2022. http:\u002F\u002Fid.nii.ac.jp\u002F1001\u002F00219408\u002F."}]}]}]}]}]},{type:a,tag:c,props:{},children:[{type:b,value:aF},{type:a,tag:i,props:{href:aG,rel:[j]},children:[{type:b,value:aH}]},{type:b,value:aI}]},{type:a,tag:c,props:{},children:[{type:b,value:aJ}]},{type:a,tag:m,props:{code:N},children:[{type:a,tag:y,props:{},children:[{type:a,tag:m,props:{__ignoreMap:k},children:[{type:a,tag:d,props:{class:q},children:[{type:a,tag:d,props:{},children:[{type:b,value:"Takuya Kawashima and Keita Watanabe. \"\"Ah-aloud\": Method for Evaluating Cognitive Processes Occurring During Tasks from Vocal Information\". 2022 8th International HCI and UX Conference in Indonesia (CHIuXiD), Vol. 2022, pp. 42-46, Jan. 2023. https:\u002F\u002Fdoi.org\u002F10.1109\u002FCHIuXiD57244.2022.10009797."}]}]}]}]}]},{type:a,tag:c,props:{},children:[{type:a,tag:i,props:{href:aK,rel:[j]},children:[{type:b,value:aL}]},{type:b,value:aM}]},{type:a,tag:B,props:{id:O},children:[{type:b,value:P}]},{type:a,tag:c,props:{},children:[{type:b,value:aN}]},{type:a,tag:c,props:{},children:[{type:b,value:aO},{type:a,tag:i,props:{href:aP,rel:[j]},children:[{type:b,value:aQ}]},{type:b,value:aR},{type:a,tag:i,props:{href:aS,rel:[j]},children:[{type:b,value:aT}]},{type:b,value:E}]},{type:a,tag:c,props:{},children:[{type:a,tag:x,props:{alt:aU,src:aV},children:[]}]},{type:a,tag:c,props:{},children:[{type:b,value:aW}]},{type:a,tag:c,props:{},children:[{type:b,value:aX}]},{type:a,tag:c,props:{},children:[{type:b,value:aY}]},{type:a,tag:c,props:{},children:[{type:b,value:aZ}]},{type:a,tag:c,props:{},children:[{type:b,value:a_}]},{type:a,tag:c,props:{},children:[{type:b,value:a$},{type:a,tag:i,props:{href:ba,rel:[j]},children:[{type:b,value:bb}]},{type:b,value:bc}]},{type:a,tag:c,props:{},children:[{type:a,tag:x,props:{alt:bd,src:be},children:[]}]},{type:a,tag:c,props:{},children:[{type:b,value:bf}]},{type:a,tag:c,props:{},children:[{type:b,value:bg}]}],toc:{title:k,searchDepth:g,depth:g,links:[{id:I,depth:g,text:J},{id:K,depth:g,text:L},{id:O,depth:g,text:P}]}},_type:t,_id:"content:article:ah-aloud.md",_source:u,_file:"article\u002Fah-aloud.md",_extension:v},{_path:"\u002Farticle\u002Fvrsj2022",_dir:r,_draft:e,_partial:e,_locale:s,_empty:e,title:"Common experience sample presented at VRSJ2022",description:"M2's Oka gave a presentation at the 27th Virtual Reality Society of Japan Conference (VRSJ2022) titled \"触覚ディスプレイの比較評価を目的とした共通体験サンプルの試作と検討\".",excerpt:{type:h,children:[]},thumbnail:"https:\u002F\u002Fstorage.googleapis.com\u002Fstudio-design-asset-files\u002Fprojects\u002FwQOVXEVxaD\u002Fs-2400x1800_v-frms_webp_9c3308d0-b234-4d70-998b-2be56b89406c.webp",exlink:"https:\u002F\u002Fkeita-lab.jp\u002Fconference\u002Fvrsj2022",created_at:"2022.09.12",updated_at:l,body:{type:h,children:[],toc:{title:k,searchDepth:g,depth:g,links:[]}},_type:t,_id:"content:article:vrsj2022.md",_source:u,_file:"article\u002Fvrsj2022.md",_extension:v},{_path:"\u002Farticle\u002Fgi47",_dir:r,_draft:e,_partial:e,_locale:s,_empty:e,title:"Open FPS presented at GI47",description:"B3 Hayashi gave a presentation titled \"FPSゲームの要素分析とそれに基づくオープンなFPSゲームの開発\" at the 47th Annual Conference on Game Informatics (gi47).",excerpt:{type:h,children:[]},thumbnail:l,exlink:"https:\u002F\u002Fwww.ipsj.or.jp\u002Fkenkyukai\u002Fevent\u002Fgi47.html#hdg2",created_at:"2022.03.18",updated_at:l,body:{type:h,children:[],toc:{title:k,searchDepth:g,depth:g,links:[]}},_type:t,_id:"content:article:gi47.md",_source:u,_file:"article\u002Fgi47.md",_extension:v},{_path:"\u002Farticle\u002Finteraction2022",_dir:r,_draft:e,_partial:e,_locale:s,_empty:e,title:"Minimum Tennis presented at Interaction 2022",description:"Iida, B2, gave a demo presentation at Interaction 2022 titled \"研究者が利用しやすいオープンなスポーツゲームの試作\".",excerpt:{type:h,children:[]},thumbnail:"https:\u002F\u002Fconfman.interaction-ipsj.org\u002Fcacheimg\u002Fi2022\u002Fi2022_2_074__9_4012_301783bdf5227fffa99b52a90ee53d65.jpg",exlink:"http:\u002F\u002Fwww.interaction-ipsj.org\u002Fproceedings\u002F2022\u002Fdata\u002Fpdf\u002F4D18.pdf",created_at:"2022.03.01",updated_at:l,body:{type:h,children:[],toc:{title:k,searchDepth:g,depth:g,links:[]}},_type:t,_id:"content:article:interaction2022.md",_source:u,_file:"article\u002Finteraction2022.md",_extension:v},{_path:"\u002Farticle\u002Fec2021",_dir:r,_draft:e,_partial:e,_locale:s,_empty:e,title:"OVGL presented at EC2021",description:"M1 student Oka gave a presentation and demonstration at Entertainment Computing 2021 titled \"研究利用しやすく標準性を目指したビデオゲームの設計と開発\".",excerpt:{type:h,children:[]},thumbnail:"http:\u002F\u002Fimg.youtube.com\u002Fvi\u002FTpbIl00uLDo\u002Fmaxresdefault.jpg",exlink:"https:\u002F\u002Ftwitter.com\u002Fkeita_lab\u002Fstatus\u002F1432621682531844098",created_at:"2021.08.31",updated_at:l,body:{type:h,children:[],toc:{title:k,searchDepth:g,depth:g,links:[]}},_type:t,_id:"content:article:ec2021.md",_source:u,_file:"article\u002Fec2021.md",_extension:v}]},prerenderedAt:1698671629835}}("element","text","p","span",false,"ct-769c3f",2,"root","a","nofollow","",null,"code","ct-5afef4","\"","li","line","article","en","markdown","content","md","h1","img","pre","   ","ct-8ee602","h2",",","https:\u002F\u002Fconference.vrsj.org\u002Fac2022\u002Fprogram\u002Fdoc\u002F1F1-5.pdf",".","bibtex","@conference{oka2022ces,\n   author    = \"拓也,岡 and 浩輔,森本 and 洋平,簗瀬 and 恵太,渡邊\",\n   title     = \"触覚ディスプレイの比較評価を目的とした共通体験サンプルの試作と検討\"\n   booktitle     = \"第27回日本バーチャルリアリティ学会大会論文集\",\n   institution  = \"明治大学大学院先端数理科学研究科先端メディアサイエンス専攻, 明治大学総合数理学部先端メディアサイエンス学科, ユニティ・テクノロジーズ・ジャパン株式会社, 明治大学総合数理学部先端メディアサイエンス学科\",\n   year      = \"2022\",\n   month     = \"sep\"\n}\n","     = ","what-is-the-ah-aloud-method","What is the Ah-Aloud Method?","conferences-and-papers-presented","Conferences and papers presented","川島 拓也, 渡邊 恵太. \"あアラウド法：体験中の心理プロセスを「あ」の音声情報で評価する手法の提案と検証\". エンタテインメントコンピューティングシンポジウム2022論文集, Vol. 2022, pp. 178-183, Aug. 2022. http:\u002F\u002Fid.nii.ac.jp\u002F1001\u002F00219408\u002F.\n","Takuya Kawashima and Keita Watanabe. \"\"Ah-aloud\": Method for Evaluating Cognitive Processes Occurring During Tasks from Vocal Information\". 2022 8th International HCI and UX Conference in Indonesia (CHIuXiD), Vol. 2022, pp. 42-46, Jan. 2023. https:\u002F\u002Fdoi.org\u002F10.1109\u002FCHIuXiD57244.2022.10009797.\n","use-cases","Use Cases","what-is-the-common-experience-sample","What is the Common Experience Sample?","https:\u002F\u002Fgithub.com\u002Fopen-video-game-library\u002FCommonExperienceSample","Common Experience Sample (CES)"," is a VR sample for evaluating tactile displays.","By using CES, visual stimuli can be shared among studies and comparative evaluations can be made.","In order to further ensure comparative evaluation, we have created a posting site to share the results of questionnaires from experiments conducted using common experience samples.","The questionnaire is embedded in CES, and the results of the questionnaire (CSV file) can be downloaded immediately after the experiment.","The questionnaire are standard equipped in the CES.","https:\u002F\u002Fuser-images.githubusercontent.com\u002F52689532\u002F223012824-b51a1035-efdb-48c4-8d27-c498eefc4b55.png","results-submission-site","Results Submission Site","https:\u002F\u002Fopen-video-game-library.github.io\u002FCommonExperienceSampleResults\u002F","Click here for link","。","Input items are as follows","ul","Sample used","Device information (URL of product page, article, etc.)","Reference device","Downloaded results data (CSV file of survey results)","Remarks","The reference device refers to the standard controller that comes with HMDs such as Oculus Quest2 and HTC Vive Pro.","By conducting experiments not only with the proposed tactile display but also with the reference device and sharing the questionnaire results, a more rigorous comparative evaluation will be possible.","Upload the survey results obtained from CES and share them with other researchers!","paper-information","Paper Information","岡拓也, 森本浩輔, 簗瀨洋平, 渡邊恵太. 触覚ディスプレイの比較評価を目的とした共通体験サンプルの試作と検討. 第 27 回日本バーチャルリアリティ学会大会論文集 (VRSJ2022). September 2022, ","iframe",560,315,"display: block; margin: 0 auto;","https:\u002F\u002Fwww.youtube.com\u002Fembed\u002FxpkJ13SegK4","YouTube video player","0","accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share",true,"The \"Ah-Aloud Method\" method is a real-time emotion observation technique.","Experimental participants express their emotions with \"ah\" concurrently with the task, and the experimenter determines the experimental participant's emotion based on the magnitude and tone of the \"ah\".","Since \"ah\"-sounding verbs are used as emotional verbs in daily life, they are considered to be suitable for expressing emotions in a natural way.","They are also useful for casual experimentation, as they use only the vocalization of \"ah\" and do not require special equipment.","We encourage you to use it in conjunction with open video games for your video game experiments.","We were invited to speak and present a demo at Entertainment Computing (EC) 2022.","Here we received the Best Paper Award and the Good Presentation Award!（","https:\u002F\u002Fscrapbox.io\u002Fec2022\u002F%E8%A1%A8%E5%BD%B0%E6%83%85%E5%A0%B1","Link","）","He also gave the English name \"ah-aloud\" and gave a presentation on stage at the 8th International HCI and UX Conference in Indonesia (CHIuXiD2023).","https:\u002F\u002Fopenvideogame.cc\u002F#publication","TOP Page",", where the papers can also be viewed.","In the course of our research on the \"Aaroud\" method, we experimented with an open video game.","The games used are ","https:\u002F\u002Fgithub.com\u002Fopen-video-game-library\u002FSlidingPenguin","Sliding Penguin"," and ","https:\u002F\u002Fgithub.com\u002Fopen-video-game-library\u002FMinimumTennis","Minimum Tennis","Sliding Penguin（左）とMinimum Tennis（右）","https:\u002F\u002Fuser-images.githubusercontent.com\u002F52689532\u002F226538593-8938b70c-5271-4ac3-8bfb-682059706c33.png","Sliding Penguin was controlled with an XBox gamepad using the standalone (Mac) version, while Minimum Tennis was controlled with a keyboard using the WebGL version.","Both video games were selected because of the emotional and thought-provoking nature of their gameplay.","Slidin Penguin is a driving game in which a penguin slides on ice. It requires continuous control and is thrilling.","Minimum Tennis is a simple tennis game. When controlled with the keyboard, the controls are complex and it is easy to get an impression of the game.","These two video games were easy to use because the Ah-Aloud Method wanted to observe emotions and thoughts.","We also used ","https:\u002F\u002Fopen-video-game-library.github.io\u002FMultiViewRecorder\u002F","Multi View Recorder"," to record the experiment.","Multi View Recorderによる実験の録画","https:\u002F\u002Fuser-images.githubusercontent.com\u002F52689532\u002F226542790-25b401ad-e6eb-4bee-b954-85b14103a035.jpeg","Multi View Recorder is a tool that allows you to record up to four videos simultaneously in your browser.","This tool was useful because we asked the experiment participants to watch the recordings and reflect on their experience during the task."))