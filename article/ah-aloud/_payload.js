export default (function(a,b,c,d,e,f,g,h,i,j,k,l,m,n,o,p,q,r,s,t,u,v,w,x,y,z,A,B,C,D,E,F,G,H,I,J,K,L,M,N,O,P,Q,R,S,T,U,V,W,X,Y,Z,_,$,aa,ab,ac,ad,ae,af,ag,ah,ai,aj,ak,al,am,an,ao,ap){return {data:{"content-query-Lj1eyIbX6c":{_path:"\u002Farticle\u002Fah-aloud",_draft:m,_partial:m,_locale:"en",_empty:m,title:"The \"Ah-Aloud Method\" was presented at an academic conference.",description:"Open video game use cases will also be presented. We have presented our method of observing emotions, called the \"Ah-Aloud Method\" at two conferences.",excerpt:{type:v,children:[{type:a,tag:g,props:{id:n},children:[{type:b,value:o}]},{type:a,tag:w,props:{width:x,height:y,style:z,src:A,title:B,frameBorder:C,allow:D,allowFullScreen:E},children:[]},{type:a,tag:c,props:{},children:[{type:b,value:F}]},{type:a,tag:c,props:{},children:[{type:b,value:G}]},{type:a,tag:c,props:{},children:[{type:b,value:H}]},{type:a,tag:c,props:{},children:[{type:b,value:I}]},{type:a,tag:c,props:{},children:[{type:b,value:J}]},{type:a,tag:g,props:{id:p},children:[{type:b,value:q}]},{type:a,tag:c,props:{},children:[{type:b,value:K}]},{type:a,tag:f,props:{code:r},children:[{type:a,tag:j,props:{},children:[{type:a,tag:f,props:{__ignoreMap:h},children:[{type:b,value:r}]}]}]},{type:a,tag:c,props:{},children:[{type:b,value:L},{type:a,tag:d,props:{href:M,rel:[e]},children:[{type:b,value:N}]},{type:b,value:O}]},{type:a,tag:c,props:{},children:[{type:b,value:P}]},{type:a,tag:f,props:{code:s},children:[{type:a,tag:j,props:{},children:[{type:a,tag:f,props:{__ignoreMap:h},children:[{type:b,value:s}]}]}]},{type:a,tag:c,props:{},children:[{type:a,tag:d,props:{href:Q,rel:[e]},children:[{type:b,value:R}]},{type:b,value:S}]},{type:a,tag:g,props:{id:t},children:[{type:b,value:u}]},{type:a,tag:c,props:{},children:[{type:b,value:T}]},{type:a,tag:c,props:{},children:[{type:b,value:U},{type:a,tag:d,props:{href:V,rel:[e]},children:[{type:b,value:W}]},{type:b,value:X},{type:a,tag:d,props:{href:Y,rel:[e]},children:[{type:b,value:Z}]},{type:b,value:_}]},{type:a,tag:c,props:{},children:[{type:a,tag:k,props:{alt:$,src:aa},children:[]}]},{type:a,tag:c,props:{},children:[{type:b,value:ab}]},{type:a,tag:c,props:{},children:[{type:b,value:ac}]},{type:a,tag:c,props:{},children:[{type:b,value:ad}]},{type:a,tag:c,props:{},children:[{type:b,value:ae}]},{type:a,tag:c,props:{},children:[{type:b,value:af}]},{type:a,tag:c,props:{},children:[{type:b,value:ag},{type:a,tag:d,props:{href:ah,rel:[e]},children:[{type:b,value:ai}]},{type:b,value:aj}]},{type:a,tag:c,props:{},children:[{type:a,tag:k,props:{alt:ak,src:al},children:[]}]},{type:a,tag:c,props:{},children:[{type:b,value:am}]},{type:a,tag:c,props:{},children:[{type:b,value:an}]}]},thumbnail:"http:\u002F\u002Fimg.youtube.com\u002Fvi\u002FxpkJ13SegK4\u002Fmaxresdefault.jpg",exlink:ao,created_at:"2022.11.19",updated_at:ao,body:{type:v,children:[{type:a,tag:g,props:{id:n},children:[{type:b,value:o}]},{type:a,tag:w,props:{width:x,height:y,style:z,src:A,title:B,frameBorder:C,allow:D,allowFullScreen:E},children:[]},{type:a,tag:c,props:{},children:[{type:b,value:F}]},{type:a,tag:c,props:{},children:[{type:b,value:G}]},{type:a,tag:c,props:{},children:[{type:b,value:H}]},{type:a,tag:c,props:{},children:[{type:b,value:I}]},{type:a,tag:c,props:{},children:[{type:b,value:J}]},{type:a,tag:g,props:{id:p},children:[{type:b,value:q}]},{type:a,tag:c,props:{},children:[{type:b,value:K}]},{type:a,tag:f,props:{code:r},children:[{type:a,tag:j,props:{},children:[{type:a,tag:f,props:{__ignoreMap:h},children:[{type:a,tag:l,props:{class:ap},children:[{type:a,tag:l,props:{},children:[{type:b,value:"川島 拓也, 渡邊 恵太. \"あアラウド法：体験中の心理プロセスを「あ」の音声情報で評価する手法の提案と検証\". エンタテインメントコンピューティングシンポジウム2022論文集, Vol. 2022, pp. 178-183, Aug. 2022. http:\u002F\u002Fid.nii.ac.jp\u002F1001\u002F00219408\u002F."}]}]}]}]}]},{type:a,tag:c,props:{},children:[{type:b,value:L},{type:a,tag:d,props:{href:M,rel:[e]},children:[{type:b,value:N}]},{type:b,value:O}]},{type:a,tag:c,props:{},children:[{type:b,value:P}]},{type:a,tag:f,props:{code:s},children:[{type:a,tag:j,props:{},children:[{type:a,tag:f,props:{__ignoreMap:h},children:[{type:a,tag:l,props:{class:ap},children:[{type:a,tag:l,props:{},children:[{type:b,value:"Takuya Kawashima and Keita Watanabe. \"\"Ah-aloud\": Method for Evaluating Cognitive Processes Occurring During Tasks from Vocal Information\". 2022 8th International HCI and UX Conference in Indonesia (CHIuXiD), Vol. 2022, pp. 42-46, Jan. 2023. https:\u002F\u002Fdoi.org\u002F10.1109\u002FCHIuXiD57244.2022.10009797."}]}]}]}]}]},{type:a,tag:c,props:{},children:[{type:a,tag:d,props:{href:Q,rel:[e]},children:[{type:b,value:R}]},{type:b,value:S}]},{type:a,tag:g,props:{id:t},children:[{type:b,value:u}]},{type:a,tag:c,props:{},children:[{type:b,value:T}]},{type:a,tag:c,props:{},children:[{type:b,value:U},{type:a,tag:d,props:{href:V,rel:[e]},children:[{type:b,value:W}]},{type:b,value:X},{type:a,tag:d,props:{href:Y,rel:[e]},children:[{type:b,value:Z}]},{type:b,value:_}]},{type:a,tag:c,props:{},children:[{type:a,tag:k,props:{alt:$,src:aa},children:[]}]},{type:a,tag:c,props:{},children:[{type:b,value:ab}]},{type:a,tag:c,props:{},children:[{type:b,value:ac}]},{type:a,tag:c,props:{},children:[{type:b,value:ad}]},{type:a,tag:c,props:{},children:[{type:b,value:ae}]},{type:a,tag:c,props:{},children:[{type:b,value:af}]},{type:a,tag:c,props:{},children:[{type:b,value:ag},{type:a,tag:d,props:{href:ah,rel:[e]},children:[{type:b,value:ai}]},{type:b,value:aj}]},{type:a,tag:c,props:{},children:[{type:a,tag:k,props:{alt:ak,src:al},children:[]}]},{type:a,tag:c,props:{},children:[{type:b,value:am}]},{type:a,tag:c,props:{},children:[{type:b,value:an}]}],toc:{title:h,searchDepth:i,depth:i,links:[{id:n,depth:i,text:o},{id:p,depth:i,text:q},{id:t,depth:i,text:u}]}},_type:"markdown",_id:"content:article:ah-aloud.md",_source:"content",_file:"article\u002Fah-aloud.md",_extension:"md"}},prerenderedAt:1698895658701}}("element","text","p","a","nofollow","code","h2","",2,"pre","img","span",false,"what-is-the-ah-aloud-method","What is the Ah-Aloud Method?","conferences-and-papers-presented","Conferences and papers presented","川島 拓也, 渡邊 恵太. \"あアラウド法：体験中の心理プロセスを「あ」の音声情報で評価する手法の提案と検証\". エンタテインメントコンピューティングシンポジウム2022論文集, Vol. 2022, pp. 178-183, Aug. 2022. http:\u002F\u002Fid.nii.ac.jp\u002F1001\u002F00219408\u002F.\n","Takuya Kawashima and Keita Watanabe. \"\"Ah-aloud\": Method for Evaluating Cognitive Processes Occurring During Tasks from Vocal Information\". 2022 8th International HCI and UX Conference in Indonesia (CHIuXiD), Vol. 2022, pp. 42-46, Jan. 2023. https:\u002F\u002Fdoi.org\u002F10.1109\u002FCHIuXiD57244.2022.10009797.\n","use-cases","Use Cases","root","iframe",560,315,"display: block; margin: 0 auto;","https:\u002F\u002Fwww.youtube.com\u002Fembed\u002FxpkJ13SegK4","YouTube video player","0","accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share",true,"The \"Ah-Aloud Method\" method is a real-time emotion observation technique.","Experimental participants express their emotions with \"ah\" concurrently with the task, and the experimenter determines the experimental participant's emotion based on the magnitude and tone of the \"ah\".","Since \"ah\"-sounding verbs are used as emotional verbs in daily life, they are considered to be suitable for expressing emotions in a natural way.","They are also useful for casual experimentation, as they use only the vocalization of \"ah\" and do not require special equipment.","We encourage you to use it in conjunction with open video games for your video game experiments.","We were invited to speak and present a demo at Entertainment Computing (EC) 2022.","Here we received the Best Paper Award and the Good Presentation Award!（","https:\u002F\u002Fscrapbox.io\u002Fec2022\u002F%E8%A1%A8%E5%BD%B0%E6%83%85%E5%A0%B1","Link","）","He also gave the English name \"ah-aloud\" and gave a presentation on stage at the 8th International HCI and UX Conference in Indonesia (CHIuXiD2023).","https:\u002F\u002Fopenvideogame.cc\u002F#publication","TOP Page",", where the papers can also be viewed.","In the course of our research on the \"Aaroud\" method, we experimented with an open video game.","The games used are ","https:\u002F\u002Fgithub.com\u002Fopen-video-game-library\u002FSlidingPenguin","Sliding Penguin"," and ","https:\u002F\u002Fgithub.com\u002Fopen-video-game-library\u002FMinimumTennis","Minimum Tennis",".","Sliding Penguin（左）とMinimum Tennis（右）","https:\u002F\u002Fuser-images.githubusercontent.com\u002F52689532\u002F226538593-8938b70c-5271-4ac3-8bfb-682059706c33.png","Sliding Penguin was controlled with an XBox gamepad using the standalone (Mac) version, while Minimum Tennis was controlled with a keyboard using the WebGL version.","Both video games were selected because of the emotional and thought-provoking nature of their gameplay.","Slidin Penguin is a driving game in which a penguin slides on ice. It requires continuous control and is thrilling.","Minimum Tennis is a simple tennis game. When controlled with the keyboard, the controls are complex and it is easy to get an impression of the game.","These two video games were easy to use because the Ah-Aloud Method wanted to observe emotions and thoughts.","We also used ","https:\u002F\u002Fopen-video-game-library.github.io\u002FMultiViewRecorder\u002F","Multi View Recorder"," to record the experiment.","Multi View Recorderによる実験の録画","https:\u002F\u002Fuser-images.githubusercontent.com\u002F52689532\u002F226542790-25b401ad-e6eb-4bee-b954-85b14103a035.jpeg","Multi View Recorder is a tool that allows you to record up to four videos simultaneously in your browser.","This tool was useful because we asked the experiment participants to watch the recordings and reflect on their experience during the task.",null,"line"))